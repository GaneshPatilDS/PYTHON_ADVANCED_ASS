{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1653d802-9c61-4800-a427-82b123c59f96",
   "metadata": {},
   "source": [
    "## QUESTIONS :\n",
    "\n",
    "1. Why would you want to use the Data API?\n",
    "\n",
    "2. What are the benefits of splitting a large dataset into multiple files?\n",
    "\n",
    "3. During training, how can you tell that your input pipeline is the bottleneck? What can you do\n",
    "   to fix it?\n",
    "   \n",
    "4. Can you save any binary data to a TFRecord file, or only serialized protocol buffers?\n",
    "\n",
    "5. Why would you go through the hassle of converting all your data to the Example protobuf\n",
    "   format? Why not use your own protobuf definition?\n",
    "   \n",
    "6. When using TFRecords, when would you want to activate compression? Why not do it\n",
    "   systematically?\n",
    "   \n",
    "7. Data can be preprocessed directly when writing the data files, or within the tf.data pipeline,\n",
    "   or in preprocessing layers within your model, or using TF Transform. Can you list a few pros\n",
    "   and cons of each option?\n",
    "   \n",
    "   ---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df884d25-005e-44df-bbbf-4f7d4ca2096a",
   "metadata": {},
   "source": [
    "ANS :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707414-7813-4bbb-b4b7-dcd9bb4f0d1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
